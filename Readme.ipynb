{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ddd0ca-dd6a-4f76-8cc9-cf4c6ad24bd1",
   "metadata": {},
   "source": [
    "# Modular Preprocessing Pipeline\n",
    "\n",
    "This is a Scikit-Learn based implementation of a feature engineering pipeline. The goal was to build a system that can be reconfigured for different datasets without touching the core transformation logic.\n",
    "\n",
    "## Key Design Choices\n",
    "* **Config-Driven**: I used a dictionary-based configuration so the pipeline can be updated via a JSON/YAML file in a production environment.\n",
    "* **Leakage Prevention**: By wrapping everything in a `Pipeline` object, we ensure that scaling parameters are calculated only on the training data.\n",
    "* **Robust Categoricals**: Set `handle_unknown='ignore'` in the encoder to prevent the system from crashing if the test set contains a category we haven't seen before.\n",
    "\n",
    "## How to Run\n",
    "1. Install dependencies: `pip install pandas scikit-learn numpy`\n",
    "2. Run the example script: `python run_pipeline.py`\n",
    "\n",
    "## Project Structure\n",
    "* `pipeline_factory.py`: Contains the logic for building the ColumnTransformer.\n",
    "* `run_pipeline.py`: A sample implementation using a mock customer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bad042-a872-4c06-b602-7d53ca38ad0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
